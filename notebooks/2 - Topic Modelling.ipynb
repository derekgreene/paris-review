{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39ac6752",
   "metadata": {},
   "source": [
    "# 2 - Topic Modelling\n",
    "\n",
    "This notebook applies NMF topic modelling to the preprocessed Paris Review data from Notebook 1 for a range of different topic numbers $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aafc670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import joblib, random\n",
    "import numpy as np\n",
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123b351d",
   "metadata": {},
   "source": [
    "Settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb84d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data paths\n",
    "dir_data = Path(\"../data\")\n",
    "dir_in = dir_data / \"proc\"\n",
    "data_prefix = \"paris\"\n",
    "data_in_path = dir_in / (\"%s.pkl\" % data_prefix)\n",
    "# output paths\n",
    "dir_out = Path(\"../models\")\n",
    "\n",
    "# topic model settings\n",
    "random_seed = 1000\n",
    "kmin, kmax = 2, 50\n",
    "kstep = 1\n",
    "init_strategy = \"nndsvd\"\n",
    "max_iters = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f80d4f8",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Read the preprocess dataset produced by Notebook 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d83a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, terms, doc_ids) = joblib.load(data_in_path)\n",
    "print(\"Loaded preprocessed data: %d documents, %d terms\" % (len(doc_ids), len(terms)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71385209",
   "metadata": {},
   "source": [
    "## Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea8e4b1",
   "metadata": {},
   "source": [
    "Function to initialize all required random seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2af022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_random_seeds(random_seed):\n",
    "    if random_seed < 0:\n",
    "        random_seed = random.randint(1,100000)\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    return random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78de128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_nmf(X, k):\n",
    "    \"\"\" Apply NMF for k topics, returning the factors and the document partition \"\"\"\n",
    "    model = decomposition.NMF(init=init_strategy, n_components=k, max_iter=max_iters)\n",
    "    W = model.fit_transform(X)\n",
    "    H = model.components_\n",
    "    partition = np.argmax(W, axis=1).flatten().tolist()\n",
    "    return (W, H, partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ddf80d",
   "metadata": {},
   "source": [
    "Function to return the top ranked terms for the specified topic, generated during the last NMF run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca74f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_terms(H, topic_index, top=-1):\n",
    "    # NB: reverse\n",
    "    top_indices = np.argsort(H[topic_index,:])[::-1]\n",
    "    # truncate if necessary\n",
    "    if top < 1 or top > len(top_indices):\n",
    "        return top_indices\n",
    "    return top_indices[0:top]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afca3617",
   "metadata": {},
   "source": [
    "Functions for saving outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c026fa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_term_rankings(out_path, term_rankings, labels=None):\n",
    "    \"\"\" Save a list of multiple term rankings using Joblib \"\"\"\n",
    "    # no labels? generate some default ones\n",
    "    if labels is None:\n",
    "        labels = []\n",
    "        for i in range(len(term_rankings)):\n",
    "            labels.append(\"C%02d\" % (i+1))\n",
    "    joblib.dump((term_rankings,labels), out_path)\n",
    "    \n",
    "def save_nmf_factors(out_path, W, H, doc_ids, terms):\n",
    "    \"\"\" Save a NMF factorization result using Joblib. \"\"\"\n",
    "    joblib.dump((W,H,doc_ids,terms), out_path) \n",
    "\n",
    "def save_partition(out_path, partition, doc_ids):\n",
    "    \"\"\"\n",
    "    Save a disjoint partition documments result using Joblib.\n",
    "    This is represent as a 0-indexed list, with one entry per document.\n",
    "    \"\"\"\n",
    "    joblib.dump((partition,doc_ids), out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c732216",
   "metadata": {},
   "source": [
    "Apply NMF for a range of values of K:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2cd0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating NMF models in range k=[%d,%d], init_strategy=%s max_iters=%d\" \n",
    "      % (kmin, kmax, init_strategy, max_iters))\n",
    "for k in range(kmin, kmax+1, kstep):\n",
    "    print(\"Applying K=%d ...\" % k)\n",
    "    # set output direcotry\n",
    "    dir_out_k = dir_out_k = dir_out / (\"nmf_k%02d\" % k)\n",
    "    dir_out_k.mkdir(parents=True, exist_ok=True)\n",
    "    # set the current random state\n",
    "    init_random_seeds(random_seed)\n",
    "    # apply NMF\n",
    "    W, H, partition = apply_nmf(X, k)\n",
    "    # get term rankings for each topic\n",
    "    term_rankings = []\n",
    "    for topic_index in range(k):\n",
    "        ranked_term_indices = rank_terms(H, topic_index)\n",
    "        term_ranking = [terms[i] for i in ranked_term_indices]\n",
    "        term_rankings.append(term_ranking)\n",
    "    # write term rankings\n",
    "    fname_ranks = \"%s_ranks.pkl\" % data_prefix\n",
    "    ranks_out_path = dir_out_k / fname_ranks\n",
    "    save_term_rankings(ranks_out_path, term_rankings)\n",
    "    # write document partition\n",
    "    fname_partition = \"%s_partition.pkl\" % data_prefix\n",
    "    partition_out_path = dir_out_k / fname_partition\n",
    "    save_partition(partition_out_path, partition, doc_ids)\n",
    "    # write the complete factorization\n",
    "    fname_factors = \"%s_factors.pkl\" % data_prefix\n",
    "    factor_out_path = dir_out_k / fname_factors\n",
    "    # NB: need to make a copy of the factors\n",
    "    save_nmf_factors(factor_out_path, np.array(W), np.array(H), doc_ids, terms)    \n",
    "    print(\"Results saved to %s\" % dir_out_k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
